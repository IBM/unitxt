import json

from unitxt import add_to_catalog
from unitxt.blocks import TaskCard
from unitxt.collections_operators import Wrap
from unitxt.image_operators import ToImage
from unitxt.loaders import LoadHF
from unitxt.operators import AddIncrementalId, Cast, Copy, FilterByCondition
from unitxt.templates import InputOutputTemplate
from unitxt.test_utils.card import test_card

description = (
    "We introduced REAL-MM-RAG-Bench, a real-world multi-modal retrieval benchmark designed to evaluate "
    "retrieval models in reliable, challenging, and realistic settings. The benchmark was constructed using "
    "an automated pipeline, where queries were generated by a vision-language model (VLM), filtered by a large "
    "language model (LLM), and rephrased by an LLM to ensure high-quality retrieval evaluation. "
    "To simulate real-world retrieval challenges, we introduce multi-level query rephrasing, modifying queries "
    "at three distinct levels—from minor wording adjustments to significant structural changes—ensuring models "
    "are tested on their true semantic understanding rather than simple keyword matching."
)

datasets = [
    {"hf_name": "REAL-MM-RAG_FinSlides", "unitxt_name": "real_mm_rag_fin_slides"},
    {"hf_name": "REAL-MM-RAG_FinReport", "unitxt_name": "real_mm_rag_fin_report"},
    {"hf_name": "REAL-MM-RAG_TechReport", "unitxt_name": "real_mm_rag_tech_report"},
    {"hf_name": "REAL-MM-RAG_TechSlides", "unitxt_name": "real_mm_rag_tech_slides"},
]

hf_ibm_research = "ibm-research"
hf_url_base = "https://huggingface.co/datasets/"

for dataset in datasets:
    hf_name = dataset["hf_name"]
    hf_dataset_id = f"{hf_ibm_research}/{hf_name}"
    hf_url = f"{hf_url_base}/{hf_dataset_id}"
    unitxt_name = dataset["unitxt_name"]

    # first we create the card for the benchmark
    card = TaskCard(
        loader=LoadHF(
            path=hf_dataset_id,
            name="default",
            split="test",
            data_classification_policy=["public"],
        ),
        preprocess_steps=[
            AddIncrementalId(to_field="reference_context_ids"),
            Cast(field="reference_context_ids", to="str"),
            FilterByCondition(values={"query": None}, condition="ne"),
            AddIncrementalId(to_field="question_id"),
            Cast(field="question_id", to="str"),
            # SplitRandomMix(
            #     {
            #         "test": "test[30%]",
            #         "train": "test[70%]",
            #     }),
            Copy(
                field_to_field={
                    "query": "question",
                },
            ),
            Wrap(
                field="answer",
                inside="list",
                to_field="reference_answers",
            ),
            Wrap(
                field="reference_context_ids",
                inside="list",
                to_field="reference_context_ids",
            ),
        ],
        task="tasks.rag.end_to_end",
        templates={"default": "templates.rag.end_to_end.json_predictions"},
        __tags__={"license": "cdla-permissive-2.0", "url": hf_url},
        __description__=description,
    )

    wrong_answer = {
        "contexts": ["hi"],
        "is_answerable": True,
        "answer": "Don't know",
        "context_ids": ["id0"],
    }

    test_card(
        card,
        strict=True,
        full_mismatch_prediction_values=[json.dumps(wrong_answer)],
        debug=False,
    )

    add_to_catalog(card, f"cards.rag.benchmark.{unitxt_name}.en", overwrite=True)

    # next we create the card for the pages (documents)
    card = TaskCard(
        loader=LoadHF(
            path=hf_dataset_id,
            name="default",
            split="test",
            data_classification_policy=["public"],
        ),
        preprocess_steps=[
            AddIncrementalId(to_field="document_id"),
            Cast(field="document_id", to="str"),
            ToImage(field="image"),
            Wrap(field="image", inside="list", to_field="passages"),
        ],
        task="tasks.rag.corpora",
        templates={
            "empty": InputOutputTemplate(
                input_format="",
                output_format="",
            ),
        },
        __tags__={"license": "cdla-permissive-2.0", "url": hf_url},
        __description__=description,
    )
    # Not testing card, because documents are not evaluated.
    add_to_catalog(card, f"cards.rag.documents.{unitxt_name}.en", overwrite=True)
