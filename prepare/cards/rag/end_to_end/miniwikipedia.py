import json

from unitxt import add_to_catalog
from unitxt.blocks import TaskCard
from unitxt.collections_operators import Wrap
from unitxt.loaders import LoadHF
from unitxt.operators import Cast, Copy
from unitxt.splitters import RenameSplits, SplitRandomMix
from unitxt.templates import InputOutputTemplate
from unitxt.test_utils.card import test_card

card = TaskCard(
    loader=LoadHF(
        path="rag-datasets/rag-mini-wikipedia",
        name="question-answer",
        data_classification_policy=["public"],
    ),
    preprocess_steps=[
        SplitRandomMix(
            {
                "train": "test[70%]",
                "test": "test[30%]",
            }
        ),
        Copy(field="id", to_field="question_id"),
        Wrap(field="answer", inside="list", to_field="reference_answers"),
    ],
    task="tasks.rag.end_to_end",
    templates={"default": "templates.rag.end_to_end.json_predictions"},
    __tags__={
        "license": "cc-by-2.5",
        "url": "https://huggingface.co/datasets/rag-datasets/rag-mini-wikipedia/",
    },
    __description__="""This dataset, a subset generated by the RAG-Datasets team, supports research in question answering by providing questions and answers derived from Wikipedia articles, along with difficulty ratings assigned by both question writers and answerers. It includes files for questions from three student cohorts (S08, S09, and S10) and 690,000 words of cleaned Wikipedia text, facilitating exploration of question generation and answering tasks.""",
)

wrong_answer = {
    "contexts": ["hi"],
    "is_answerable": True,
    "answer": "Don't know",
    "context_ids": ["id0"],
}
test_card(
    card,
    strict=True,
    full_mismatch_prediction_values=[json.dumps(wrong_answer)],
    debug=False,
    demos_taken_from="test",
    demos_pool_size=5,
)

add_to_catalog(card, "cards.rag.benchmark.miniwiki.en", overwrite=True)

# Documents

card = TaskCard(
    loader=LoadHF(
        path="rag-datasets/rag-mini-wikipedia",
        name="text-corpus",
        data_classification_policy=["public"],
    ),
    preprocess_steps=[
        RenameSplits(
            {
                "passages": "train",
            }
        ),
        Cast(field="id", to="str", to_field="document_id"),
        Wrap(field="passage", inside="list", to_field="passages"),
    ],
    task="tasks.rag.corpora",
    templates={
        "empty": InputOutputTemplate(
            input_format="",
            output_format="",
        ),
    },
    __tags__={
        "license": "cc-by-2.5",
        "url": "https://huggingface.co/datasets/rag-datasets/rag-mini-wikipedia/",
    },
    __description__="""This dataset, a subset generated by the RAG-Datasets team, supports research in question answering by providing questions and answers derived from Wikipedia articles, along with difficulty ratings assigned by both question writers and answerers. It includes files for questions from three student cohorts (S08, S09, and S10) and 690,000 words of cleaned Wikipedia text, facilitating exploration of question generation and answering tasks.""",
)

add_to_catalog(card, "cards.rag.documents.miniwiki.en", overwrite=True)
