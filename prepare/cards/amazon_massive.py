from unitxt.blocks import (
    LoadHF,
    MapInstanceValues,
    Rename,
    Set,
    TaskCard,
)
from unitxt.catalog import add_to_catalog
from unitxt.test_utils.card import test_card

langs = [
    "af-ZA",
    "am-ET",
    "ar-SA",
    "az-AZ",
    "bn-BD",
    "ca-ES",
    "cy-GB",
    "da-DK",
    "de-DE",
    "el-GR",
    "en-US",
    "es-ES",
    "fa-IR",
    "fi-FI",
    "fr-FR",
    "he-IL",
    "hi-IN",
    "hu-HU",
    "hy-AM",
    "id-ID",
    "is-IS",
    "it-IT",
    "ja-JP",
    "jv-ID",
    "ka-GE",
    "km-KH",
    "kn-IN",
    "ko-KR",
    "lv-LV",
    "ml-IN",
    "mn-MN",
    "ms-MY",
    "my-MM",
    "nb-NO",
    "nl-NL",
    "pl-PL",
    "pt-PT",
    "ro-RO",
    "ru-RU",
    "sl-SL",
    "sq-AL",
    "sv-SE",
    "sw-KE",
    "ta-IN",
    "te-IN",
    "th-TH",
    "tl-PH",
    "tr-TR",
    "ur-PK",
    "vi-VN",
    "zh-CN",
    "zh-TW",
    "all",
    "all_1.1",
]
class_names = [
    "datetime_query",
    "iot_hue_lightchange",
    "transport_ticket",
    "takeaway_query",
    "qa_stock",
    "general_greet",
    "recommendation_events",
    "music_dislikeness",
    "iot_wemo_off",
    "cooking_recipe",
    "qa_currency",
    "transport_traffic",
    "general_quirky",
    "weather_query",
    "audio_volume_up",
    "email_addcontact",
    "takeaway_order",
    "email_querycontact",
    "iot_hue_lightup",
    "recommendation_locations",
    "play_audiobook",
    "lists_createoradd",
    "news_query",
    "alarm_query",
    "iot_wemo_on",
    "general_joke",
    "qa_definition",
    "social_query",
    "music_settings",
    "audio_volume_other",
    "calendar_remove",
    "iot_hue_lightdim",
    "calendar_query",
    "email_sendemail",
    "iot_cleaning",
    "audio_volume_down",
    "play_radio",
    "cooking_query",
    "datetime_convert",
    "qa_maths",
    "iot_hue_lightoff",
    "iot_hue_lighton",
    "transport_query",
    "music_likeness",
    "email_query",
    "play_music",
    "audio_volume_mute",
    "social_post",
    "alarm_set",
    "qa_factoid",
    "calendar_set",
    "play_game",
    "alarm_remove",
    "lists_remove",
    "transport_taxi",
    "recommendation_movies",
    "iot_coffee",
    "music_query",
    "play_podcasts",
    "lists_query",
]

mappers = {f"{i}": name for i, name in enumerate(class_names)}


for lang in langs:
    card = TaskCard(
        loader=LoadHF(
            path="AmazonScience/massive",
            revision="refs/convert/parquet",
            data_dir=lang,
            splits=["train", "test", "validation"],
        ),
        preprocess_steps=[
            MapInstanceValues(mappers={"intent": mappers}),
            Rename(field_to_field={"utt": "text", "intent": "label"}),
            Set(
                fields={
                    "classes": class_names,
                    "text_type": "sentence",
                    "type_of_class": "intent",
                }
            ),
        ],
        task="tasks.classification.multi_class",
        templates="templates.classification.multi_class.all",
        __tags__={
            "annotations_creators": "expert-generated",
            "arxiv": "2204.08582",
            "flags": ["natural-language-understanding"],
            "language_creators": "found",
            "license": "cc-by-4.0",
            "multilinguality": [
                "af-ZA",
                "am-ET",
                "ar-SA",
                "az-AZ",
                "bn-BD",
                "ca-ES",
                "cy-GB",
                "da-DK",
                "de-DE",
                "el-GR",
                "en-US",
                "es-ES",
                "fa-IR",
                "fi-FI",
                "fr-FR",
                "he-IL",
                "hi-IN",
                "hu-HU",
                "hy-AM",
                "id-ID",
                "is-IS",
                "it-IT",
                "ja-JP",
                "jv-ID",
                "ka-GE",
                "km-KH",
                "kn-IN",
                "ko-KR",
                "lv-LV",
                "ml-IN",
                "mn-MN",
                "ms-MY",
                "my-MM",
                "nb-NO",
                "nl-NL",
                "pl-PL",
                "pt-PT",
                "ro-RO",
                "ru-RU",
                "sl-SL",
                "sq-AL",
                "sv-SE",
                "sw-KE",
                "ta-IN",
                "te-IN",
                "th-TH",
                "tl-PH",
                "tr-TR",
                "ur-PK",
                "vi-VN",
                "zh-CN",
                "zh-TW",
            ],
            "region": "us",
            "size_categories": "100K<n<1M",
            "source_datasets": "original",
            "task_categories": "text-classification",
            "task_ids": ["intent-classification", "multi-class-classification"],
        },
        __description__=(
            "MASSIVE is a parallel dataset of > 1M utterances across 51 languages with annotations for the Natural Language Understanding tasks of intent prediction and slot annotation. Utterances span 60 intents and include 55 slot types. MASSIVE was created by localizing the SLURP dataset, composed of general Intelligent Voice Assistant single-shot interactions. See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/massive."
        ),
    )

    if lang == langs[0]:
        test_card(card, debug=False)
    filename = lang.replace("-", "_")
    add_to_catalog(card, f"cards.amazon_mass.{filename}", overwrite=True)
