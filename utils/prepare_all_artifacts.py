from datasets import load_dataset as hf_load_dataset
from unitxt import get_logger
from unitxt.api import _source_to_dataset, load_recipe
from unitxt.artifact import fetch_artifact

logger = get_logger()

card_name = "cards.frames"
logger.critical(f"card tested: {card_name}. only _source_to_dataset")

card, _ = fetch_artifact(card_name)
ds = hf_load_dataset(path=card.loader.path)
logger.critical(f"ds as read by datasets.load_dataset:\n{ds}")
for split_name in ds.keys():
    cntr = 0
    for _ in ds[split_name]:
        cntr = cntr + 1
    logger.critical(
        f"len of train split {split_name}, read by datasets.load_dataset: {cntr}"
    )
recipe = load_recipe(card=card_name)
loader = recipe.steps[0].steps[0]
logger.critical(f"unitxt loader.path = {loader.path}")
ms = loader()
logger.critical(f"splits of ms=loader(): {ms.keys()}")
for split_name in ms.keys():
    cntr = 0
    for _ in ms[split_name]:
        cntr = cntr + 1
    logger.critical(f"len of split {split_name}, read by unitxt.recipe.loader: {cntr}")
ms = recipe()
logger.critical(f"splits of ms=recipe(): {ms.keys()}")
for split_name in ms.keys():
    cntr = 0
    for _ in ms[split_name]:
        cntr = cntr + 1
    logger.critical(f"len of split {split_name}, read by unitxt.recipe: {cntr}")
logger.critical("now trying: ds = _source_to_dataset(source=recipe)")
ds = _source_to_dataset(source=recipe)
logger.critical(f"ds as generated by _source_to_dataset:\n{ds}")
