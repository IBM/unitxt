from datasets import load_dataset as hf_load_dataset
from unitxt import get_logger
from unitxt.api import _source_to_dataset, load_recipe
from unitxt.artifact import fetch_artifact

logger = get_logger()

card, _ = fetch_artifact("cards.info_vqa")
ds = hf_load_dataset(path=card.loader.path)
logger.critical(f"ds as read by datasets.load_dataset:\n{ds}")
cntr = 0
for _ in ds["train"]:
    cntr = cntr + 1
logger.critical(f"len of train split, read by datasets.load_dataset: {cntr}")
recipe = load_recipe(card="cards.info_vqa")
loader = recipe.steps[0].steps[0]
logger.critical(f"unitxt loader.path = {loader.path}")
ms = loader()
logger.critical(f"splits of ms=loader(): {ms.keys()}")
cntr = 0
for _ in ms["train"]:
    cntr = cntr + 1
logger.critical(f"len of train split, read by unitxt.recipe.loader: {cntr}")
ms = recipe()
logger.critical(f"splits of ms=recipe(): {ms.keys()}")
cntr = 0
for _ in ms["train"]:
    cntr = cntr + 1
logger.critical(f"len of train split, read by unitxt.recipe: {cntr}")
cntr = 0
for _ in ms["test"]:
    cntr = cntr + 1
logger.critical(f"len of test split, read by unitxt.recipe: {cntr}")
cntr = 0
for _ in ms["validation"]:
    cntr = cntr + 1
logger.critical(f"len of validation split, read by unitxt.recipe: {cntr}")
logger.critical("now trying: ds = _source_to_dataset(source=recipe)")
ds = _source_to_dataset(source=recipe)
logger.critical(f"ds as generated by _source_to_dataset:\n{ds}")
