import filecmp
import glob
import importlib.util
import os
import shutil
from collections import defaultdict
from pathlib import Path

from unitxt import get_logger
from unitxt.settings_utils import get_constants, get_settings

logger = get_logger()
constants = get_constants()
settings = get_settings()


def import_module_from_file(file_path):
    # Get the module name (file name without extension)
    module_name = os.path.splitext(os.path.basename(file_path))[0]
    # Create a module specification
    spec = importlib.util.spec_from_file_location(module_name, file_path)
    # Create a new module based on the specification
    module = importlib.util.module_from_spec(spec)
    # Load the module
    logger.info(
        f"allow unverified code in {file_path} : {settings.allow_unverified_code}"
    )
    spec.loader.exec_module(module)
    return module


# flake8: noqa: C901
def main():
    catalog_dir = constants.catalog_dir
    catalog_back_dir = catalog_dir + "_back"

    os.environ["UNITXT_USE_ONLY_LOCAL_CATALOGS"] = "True"
    os.environ["UNITXT_TEST_CARD_DISABLE"] = "True"
    os.environ["UNITXT_TEST_METRIC_DISABLE"] = "True"
    os.environ["UNITXT_ALLOW_UNVERIFIED_CODE"] = "True"
    os.environ["UNITXT_SKIP_ARTIFACTS_PREPARE_AND_VERIFY"] = "True"
    logger.info("*" * 100)
    logger.info("*" * 100)
    logger.info(
        "Copying all files from 'src/unitxt/catalog' to a backup 'src/unitxt/catalog_back'"
    )
    shutil.rmtree(catalog_back_dir, ignore_errors=True)
    shutil.copytree(catalog_dir, catalog_back_dir)

    logger.critical("Starting to reprepare the catalog...")
    prepare_dir = os.path.join(Path(catalog_dir).parent.parent.parent, "prepare")
    prepare_files = sorted(glob.glob(f"{prepare_dir}/**/*.py", recursive=True))
    failing_prepare_files = []
    prepare_files_generating_entries_not_in_the_catalog = []
    prepare_files_generating_entries_of_different_content_from_what_is_in_the_catalog = []
    catalog_files_generated_thus_far = defaultdict(
        list
    )  # from catalog_file to list of its generators
    current_catalog_files = glob.glob(f"{catalog_dir}/**/*.json", recursive=True)
    initial_time = os.path.getmtime(catalog_dir)
    for current_catalog_file in current_catalog_files:
        if os.path.getmtime(current_catalog_file) > initial_time:
            initial_time = os.path.getmtime(current_catalog_file)
    # initial_time is the most recent modification time of any catalog file
    next_border_time = initial_time
    for i, prepare_file in enumerate(prepare_files):
        logger.info("*" * 100)
        logger.info(f"* {i}/{len(prepare_files)}: {prepare_file}")
        logger.info("*")
        border_time = next_border_time
        try:
            import_module_from_file(prepare_file)
            current_catalog_files = glob.glob(
                f"{catalog_dir}/**/*.json", recursive=True
            )
            new_times = []  # modification times of catalog files changed by prepare_file
            for current_catalog_file in current_catalog_files:
                if (
                    os.path.getmtime(current_catalog_file) > border_time
                ):  # current_catalog_file was just generated by prepare_file
                    new_times.append(os.path.getmtime(current_catalog_file))
                    catalog_files_generated_thus_far[current_catalog_file].append(
                        prepare_file
                    )
                    if not os.path.exists(
                        current_catalog_file.replace(catalog_dir, catalog_back_dir)
                    ):
                        # prepare_file generates a catalog file that is not a member of branch's original catalog
                        prepare_files_generating_entries_not_in_the_catalog.append(
                            prepare_file
                        )
                        # return branch's catalog to its original state:
                        os.remove(current_catalog_file)
                    elif not filecmp.cmp(
                        current_catalog_file,
                        current_catalog_file.replace(catalog_dir, catalog_back_dir),
                        shallow=False,
                    ):
                        # prepare_file generates a catalog file that is different from the existing branch's catalog file of same name
                        prepare_files_generating_entries_of_different_content_from_what_is_in_the_catalog.append(
                            prepare_file
                        )
                        # restore current_catalog_file from backup catalog.
                        shutil.copy(
                            current_catalog_file.replace(catalog_dir, catalog_back_dir),
                            current_catalog_file,
                        )
                        # modification time of current_catalog_file is now - the time of copying
                        new_times.append(os.path.getmtime(current_catalog_file))

            if new_times:
                # several prepare files are all commented out, waiting for a fix
                next_border_time = max(new_times)

        except Exception as e:
            logger.info(f"Failed to run prepare file: {prepare_file}")
            failing_prepare_files.append((prepare_file, e))

    # report errors discovered thus far
    if failing_prepare_files:
        logger.critical(
            f"Execution of the following {len(failing_prepare_files)} prepare files failed for the following respective causes:"
        )
        for prepare_file, e in failing_prepare_files:
            logger.critical(
                f"prepare file: '{prepare_file}' failed, throwing exception: '{e}'"
            )

    if prepare_files_generating_entries_not_in_the_catalog:
        prepare_files_generating_entries_not_in_the_catalog = sorted(
            set(prepare_files_generating_entries_not_in_the_catalog)
        )
        logger.critical(
            f"The following {len(prepare_files_generating_entries_not_in_the_catalog)} prepare files generated catalog files that are not included in the catalog. To fix: add the products of these prepare files to the catalog."
        )
        for prepare_file in prepare_files_generating_entries_not_in_the_catalog:
            logger.critical(f"{prepare_file}")

    if prepare_files_generating_entries_of_different_content_from_what_is_in_the_catalog:
        prepare_files_generating_entries_of_different_content_from_what_is_in_the_catalog = sorted(
            set(
                prepare_files_generating_entries_of_different_content_from_what_is_in_the_catalog
            )
        )
        logger.critical(
            f"The following {len(prepare_files_generating_entries_of_different_content_from_what_is_in_the_catalog)} prepare files generated catalog files of different contents from what is included in the (original branch's) catalog. To fix: update the branch's catalog files by the products of these prepare files."
        )
        for prepare_file in prepare_files_generating_entries_of_different_content_from_what_is_in_the_catalog:
            logger.critical(f"{prepare_file}")

    # see if the branch's catalog contains any file that none of the branch's prepare file generates:
    catalog_files_not_generated_by_any_prepare_file = []
    current_catalog_files = glob.glob(f"{catalog_dir}/**/*.json", recursive=True)
    for current_catalog_file in current_catalog_files:
        if (
            os.path.getmtime(current_catalog_file) > initial_time
        ):  # current_catalog_file was touched by a prepare file
            continue
        catalog_files_not_generated_by_any_prepare_file.append(current_catalog_file)

    if catalog_files_not_generated_by_any_prepare_file:
        logger.critical(
            f"The following {len(catalog_files_not_generated_by_any_prepare_file)} branch's catalog files are not generated by any of the branch's prepare files. To fix: remove them from the branch's catalog."
        )
        for catalog_file in catalog_files_not_generated_by_any_prepare_file:
            logger.critical(f"{catalog_file}")

    catalog_files_generated_by_more_than_one_prepare_files = [
        catalog_file
        for catalog_file in catalog_files_generated_thus_far
        if len(catalog_files_generated_thus_far[catalog_file]) > 1
    ]
    if catalog_files_generated_by_more_than_one_prepare_files:
        logger.critical(
            f"Each of the following {len(catalog_files_generated_by_more_than_one_prepare_files)} catalog files were generated by more than one prepare file. To fix: remove exessive branch's prepare files."
        )
        for catalog_file in catalog_files_generated_by_more_than_one_prepare_files:
            logger.critical(
                f"{catalog_file} is generated by: {catalog_files_generated_thus_far[catalog_file]}"
            )

    # finally, restore branch's catalog, including modification times
    shutil.rmtree(catalog_dir, ignore_errors=True)
    shutil.copytree(catalog_back_dir, catalog_dir)
    shutil.rmtree(catalog_back_dir, ignore_errors=True)

    if failing_prepare_files:
        raise RuntimeError(
            "Checking consistency of branch's catalog against the total production of the branch's prepare files, we run each prepare file in turn, given the branch's catalog (which is needed as input by many of the prepare files). Some of the prepare files failed running. See details in the logs."
        )

    if (
        catalog_files_not_generated_by_any_prepare_file
        or prepare_files_generating_entries_not_in_the_catalog
        or prepare_files_generating_entries_of_different_content_from_what_is_in_the_catalog
        or catalog_files_generated_by_more_than_one_prepare_files
    ):
        raise RuntimeError(
            "Branch's catalog is different from the total production of branch's prepare files. See details in the logs."
        )

    logger.critical(
        "Done. Catalog is consistent with the total production of the prepare files."
    )


if __name__ == "__main__":
    main()
