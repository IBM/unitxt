{
    "__type__": "rits_inference_engine",
    "model_name": "meta-llama/llama-3-1-405b-instruct-fp8",
    "logprobs": true,
    "max_tokens": 5,
    "temperature": 0.0
}
