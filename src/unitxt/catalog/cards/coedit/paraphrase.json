{
    "type": "task_card",
    "loader": {
        "type": "load_hf",
        "path": "grammarly/coedit",
        "streaming": true,
        "filtering_lambda": "lambda x: x['task'] == 'paraphrase'"
    },
    "preprocess_steps": [
        "splitters.small_no_test",
        {
            "type": "split",
            "field": "src",
            "by": ": "
        },
        {
            "type": "slice",
            "field": "src",
            "start": 1
        },
        {
            "type": "join",
            "field": "src",
            "by": ": "
        },
        {
            "type": "add_fields",
            "fields": {
                "text_type": "sentence"
            }
        },
        {
            "type": "rename_fields",
            "field_to_field": {
                "tgt": "output_text",
                "src": "input_text"
            }
        }
    ],
    "task": "tasks.rewriting.paraphrase",
    "templates": "templates.rewriting.paraphrase.all",
    "__tags__": {
        "arxiv": "2305.09857",
        "croissant": true,
        "language": "en",
        "license": "apache-2.0",
        "region": "us",
        "size_categories": "10K<n<100K",
        "task_categories": "text-generation"
    },
    "__description__": "Dataset Card for CoEdIT: Text Editing via Instruction Tuning\nPaper: CoEdIT: Text Editing by Task-Specific Instruction Tuning\nAuthors: Vipul Raheja, Dhruv Kumar, Ryan Koo, Dongyeop Kang\nProject Repo: https://github.com/vipulraheja/coedit\nDataset Summary\nThis is the dataset that was used to train the CoEdIT text editing models. Full details of the dataset can be found in our paper.\nDataset Structure\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/grammarly/coedit."
}
