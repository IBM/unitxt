{
    "__type__": "task_card",
    "loader": {
        "__type__": "load_json_file",
        "files": {
            "test": "https://raw.githubusercontent.com/dmg-illc/JUDGE-BENCH/refs/heads/master/data/inferential-strategies/inferential_strategies.json"
        },
        "data_classification_policy": [
            "public"
        ],
        "data_field": "instances"
    },
    "preprocess_steps": [
        {
            "__type__": "group_dict_with_regex",
            "field": "instance",
            "pattern": ".*?### PROBLEM STATEMENT\\s+(?P<problem_statement>.*?)\\s+Statements:\\s+(?P<statements>.*?)\\s+Let\\'s think step by step\\.\\s*### MODEL RESPONSE\\s+(?P<model_reasoning>.*)",
            "flags": 16
        },
        {
            "__type__": "filter_by_condition",
            "values": {
                "instance/problem_statement": true
            },
            "condition": "exists"
        },
        {
            "__type__": "rename",
            "field_to_field": {
                "instance/problem_statement": "problem statement",
                "instance/statements": "statements",
                "instance/model_reasoning": "model reasoning",
                "annotations/Sound Reasoning/majority_human": "label"
            }
        },
        {
            "__type__": "map_instance_values",
            "mappers": {
                "label": {
                    "no": "No",
                    "yes": "Yes"
                }
            }
        },
        {
            "__type__": "copy",
            "field": "label",
            "to_field": "label_value"
        },
        {
            "__type__": "map_instance_values",
            "mappers": {
                "label_value": {
                    "Yes": 1.0,
                    "No": 0.0
                }
            }
        },
        {
            "__type__": "set",
            "fields": {
                "criteria": "metrics.llm_as_judge.direct.criteria.logical_validity_of_reasoning"
            }
        }
    ],
    "task": {
        "__type__": "task",
        "input_fields": {
            "problem statement": "str",
            "statements": "str",
            "model reasoning": "str",
            "label": "str",
            "criteria": "Any"
        },
        "reference_fields": {
            "label_value": "float"
        },
        "prediction_type": "float",
        "metrics": [
            "metrics.accuracy",
            "metrics.f1_macro"
        ],
        "default_template": "templates.empty[postprocessors=[processors.cast_to_float_return_nan_if_failed]]"
    },
    "templates": []
}
