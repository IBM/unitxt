{
    "__type__": "task_card",
    "loader": {
        "__type__": "load_hf",
        "path": "rootsautomation/websrc"
    },
    "preprocess_steps": [
        {
            "__type__": "rename_splits",
            "mapper": {
                "train": "train",
                "dev": "test"
            }
        },
        "splitters.small_no_dev",
        {
            "__type__": "wrap",
            "field": "answer",
            "inside": "list",
            "to_field": "answers"
        },
        {
            "__type__": "decode_image",
            "field": "image",
            "to_field": "context"
        },
        {
            "__type__": "set",
            "fields": {
                "context_type": "image"
            }
        }
    ],
    "task": "tasks.qa.with_context.abstractive",
    "templates": "templates.qa.with_context.all",
    "__tags__": {
        "license": "Unknown",
        "multilinguality": "monolingual",
        "modalities": [
            "image",
            "text"
        ],
        "size_categories": "10K<n<100K",
        "task_categories": "question-answering",
        "task_ids": "extractive-qa"
    },
    "__description__": "WebSRC v1.0 is a dataset for reading comprehension on structural web pages. The task is to answer questions about web pages, which requires a system to have a comprehensive understanding of the spatial structure and logical structure. WebSRC consists of 6.4K web pages and 400K question-answer pairs about web pages. This cached copy of the dataset is focused on Q&A using the web screenshots (HTML and other metadata are omitted). Questions in WebSRC were created for each segment. Answers are either text spans from web pages or yes/no."
}
