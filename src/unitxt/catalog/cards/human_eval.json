{
    "type": "task_card",
    "loader": {
        "type": "load_hf",
        "path": "openai_humaneval",
        "split": "test"
    },
    "preprocess_steps": [
        {
            "type": "execute_expression",
            "expression": "[t for t in re.findall(r\"assert.*?(?=\\n\\s*assert|$)\", test.replace(\"candidate\", entry_point), re.DOTALL)]",
            "imports_list": [
                "re"
            ],
            "to_field": "test_list"
        }
    ],
    "task": {
        "type": "form_task",
        "inputs": [
            "prompt"
        ],
        "outputs": [
            "prompt",
            "canonical_solution",
            "test_list"
        ],
        "metrics": [
            "metrics.bleu"
        ]
    },
    "templates": {
        "type": "templates_list",
        "items": [
            {
                "type": "input_output_template",
                "input_format": "{prompt}\n",
                "output_format": "{prompt}\n{canonical_solution}"
            }
        ]
    },
    "__tags__": {
        "dataset_info_tags": [
            "task_categories:text2text-generation",
            "annotations_creators:expert-generated",
            "language_creators:expert-generated",
            "multilinguality:monolingual",
            "size_categories:n<1K",
            "source_datasets:original",
            "language:en",
            "license:mit",
            "code-generation",
            "croissant",
            "arxiv:2107.03374",
            "region:us"
        ]
    }
}
