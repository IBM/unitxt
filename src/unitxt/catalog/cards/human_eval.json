{
    "type": "task_card",
    "loader": {
        "type": "load_hf",
        "path": "openai_humaneval",
        "split": "test"
    },
    "preprocess_steps": [
        {
            "type": "execute_expression",
            "expression": "[t for t in re.findall(r\"assert.*?(?=\\n\\s*assert|$)\", test.replace(\"candidate\", entry_point), re.DOTALL)]",
            "imports_list": [
                "re"
            ],
            "to_field": "test_list"
        }
    ],
    "task": {
        "type": "task",
        "inputs": [
            "prompt"
        ],
        "outputs": [
            "prompt",
            "canonical_solution",
            "test_list"
        ],
        "metrics": [
            "metrics.bleu"
        ]
    },
    "templates": {
        "type": "templates_list",
        "items": [
            {
                "type": "input_output_template",
                "input_format": "{prompt}\n",
                "output_format": "{prompt}\n{canonical_solution}"
            }
        ]
    },
    "__tags__": {
        "annotations_creators": "expert-generated",
        "arxiv": "2107.03374",
        "code-generation": true,
        "croissant": true,
        "language": "en",
        "language_creators": "expert-generated",
        "license": "mit",
        "multilinguality": "monolingual",
        "region": "us",
        "size_categories": "n<1K",
        "source_datasets": "original",
        "task_categories": "text2text-generation"
    },
    "__description__": "Dataset Card for OpenAI HumanEval\nDataset Summary\nThe HumanEval dataset released by OpenAI includes 164 programming problems with a function sig- nature, docstring, body, and several unit tests. They were handwritten to ensure not to be included in the training set of code generation models.\nSupported Tasks and Leaderboards\nLanguages\nThe programming problems are written in Python and contain English natural text in comments andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openai_humaneval."
}
