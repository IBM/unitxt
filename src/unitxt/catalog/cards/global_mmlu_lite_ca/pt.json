{
    "__type__": "task_card",
    "loader": {
        "__type__": "load_hf",
        "path": "CohereForAI/Global-MMLU-Lite",
        "name": "pt",
        "filtering_lambda": "lambda x: x['cultural_sensitivity_label'] == 'CA'"
    },
    "preprocess_steps": [
        {
            "__type__": "split_random_mix",
            "mix": {
                "test": "test[100%]",
                "train": "test[10%]"
            }
        },
        {
            "__type__": "deduplicate",
            "by": [
                "question",
                "subject",
                "answer"
            ]
        },
        {
            "__type__": "map_instance_values",
            "mappers": {
                "answer": {
                    "A": 0,
                    "B": 1,
                    "C": 2,
                    "D": 3
                }
            }
        },
        {
            "__type__": "list_field_values",
            "fields": [
                "option_a",
                "option_b",
                "option_c",
                "option_d"
            ],
            "to_field": "choices"
        },
        {
            "__type__": "rename",
            "field_to_field": {
                "subject": "topic"
            }
        },
        {
            "__type__": "map_instance_values",
            "mappers": {
                "topic": {
                    "abstract_algebra": "abstract algebra",
                    "anatomy": "anatomy",
                    "astronomy": "astronomy",
                    "business_ethics": "business ethics",
                    "clinical_knowledge": "clinical knowledge",
                    "college_biology": "college biology",
                    "college_chemistry": "college chemistry",
                    "college_computer_science": "college computer science",
                    "college_mathematics": "college mathematics",
                    "college_medicine": "college medicine",
                    "college_physics": "college physics",
                    "computer_security": "computer security",
                    "conceptual_physics": "conceptual physics",
                    "econometrics": "econometrics",
                    "electrical_engineering": "electrical engineering",
                    "elementary_mathematics": "elementary mathematics",
                    "formal_logic": "formal logic",
                    "global_facts": "global facts",
                    "high_school_biology": "high school biology",
                    "high_school_chemistry": "high school chemistry",
                    "high_school_computer_science": "high school computer science",
                    "high_school_european_history": "high school european history",
                    "high_school_geography": "high school geography",
                    "high_school_government_and_politics": "high school government and politics",
                    "high_school_macroeconomics": "high school macroeconomics",
                    "high_school_mathematics": "high school mathematics",
                    "high_school_microeconomics": "high school microeconomics",
                    "high_school_physics": "high school physics",
                    "high_school_psychology": "high school psychology",
                    "high_school_statistics": "high school statistics",
                    "high_school_us_history": "high school us history",
                    "high_school_world_history": "high school world history",
                    "human_aging": "human aging",
                    "human_sexuality": "human sexuality",
                    "international_law": "international law",
                    "jurisprudence": "jurisprudence",
                    "logical_fallacies": "logical fallacies",
                    "machine_learning": "machine learning",
                    "management": "management",
                    "marketing": "marketing",
                    "medical_genetics": "medical genetics",
                    "miscellaneous": "miscellaneous",
                    "moral_disputes": "moral disputes",
                    "moral_scenarios": "moral scenarios",
                    "nutrition": "nutrition",
                    "philosophy": "philosophy",
                    "prehistory": "prehistory",
                    "professional_accounting": "professional accounting",
                    "professional_law": "professional law",
                    "professional_medicine": "professional medicine",
                    "professional_psychology": "professional psychology",
                    "public_relations": "public relations",
                    "security_studies": "security studies",
                    "sociology": "sociology",
                    "us_foreign_policy": "us foreign policy",
                    "virology": "virology",
                    "world_religions": "world religions"
                }
            }
        }
    ],
    "task": "tasks.qa.multiple_choice.with_topic",
    "templates": "templates.qa.multiple_choice.with_topic.all",
    "__tags__": {
        "annotations_creators": "expert-generated",
        "language": "pt",
        "language_creators": "expert-generated",
        "license": "apache-2.0",
        "multilinguality": "multilingual",
        "size_categories": "10K<n<100K",
        "source_datasets": "original",
        "task_categories": "question-answering",
        "task_ids": "multiple-choice-qa",
        "region": "global"
    },
    "__description__": "Global-MMLU-Lite is a streamlined multilingual evaluation set covering 15 languages. The dataset includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) questions per language. The samples in Global-MMLU-Lite correspond to languages that were fully human-translated or post-edited in the original dataset. This initiative was led by Cohere For AI in collaboration with external contributors from industry and academia. The test spans subjects in humanities, social sciences, hard sciences, and other areas. For more information, see: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite"
}
