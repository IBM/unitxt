{
    "__type__": "task_card",
    "loader": {
        "__type__": "load_hf",
        "path": "papluca/language-identification"
    },
    "preprocess_steps": [
        {
            "__type__": "rename",
            "field_to_field": {
                "labels": "label"
            }
        },
        {
            "__type__": "map_instance_values",
            "mappers": {
                "label": {
                    "ar": "arabic",
                    "bg": "bulgarian",
                    "de": "german",
                    "el": "modern greek",
                    "en": "english",
                    "es": "spanish",
                    "fr": "french",
                    "hi": "hindi",
                    "it": "italian",
                    "ja": "japanese",
                    "nl": "dutch",
                    "pl": "polish",
                    "pt": "portuguese",
                    "ru": "russian",
                    "sw": "swahili",
                    "th": "thai",
                    "tr": "turkish",
                    "ur": "urdu",
                    "vi": "vietnamese",
                    "zh": "chinese"
                }
            }
        }
    ],
    "task": "tasks.language_identification",
    "templates": "templates.language_identification.all",
    "__description__": "The Language Identification dataset is a collection of 90k samples consisting of text passages and corresponding language label. This dataset was created by collecting data from 3 sources: Multilingual Amazon Reviews Corpus, XNLI, and STSb Multi MT. See the full description on the dataset page: https://huggingface.co/datasets/papluca/language-identification."
}
