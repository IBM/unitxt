{
    "__type__": "task_card",
    "loader": {
        "__type__": "load_hf",
        "path": "CohereForAI/Global-MMLU",
        "name": "pt"
    },
    "preprocess_steps": [
        {
            "__type__": "filter_by_condition",
            "values": {
                "subject": "college_medicine"
            },
            "condition": "eq"
        },
        {
            "__type__": "deduplicate",
            "by": [
                "question",
                "subject",
                "answer"
            ]
        },
        {
            "__type__": "rename_splits",
            "mapper": {
                "dev": "train"
            }
        },
        {
            "__type__": "map_instance_values",
            "mappers": {
                "answer": {
                    "A": 0,
                    "B": 1,
                    "C": 2,
                    "D": 3
                }
            }
        },
        {
            "__type__": "list_field_values",
            "fields": [
                "option_a",
                "option_b",
                "option_c",
                "option_d"
            ],
            "to_field": "choices"
        },
        {
            "__type__": "set",
            "fields": {
                "topic": "college medicine"
            }
        }
    ],
    "task": "tasks.qa.multiple_choice.with_topic",
    "templates": "templates.qa.multiple_choice.with_topic.all",
    "__tags__": {
        "annotations_creators": "expert-generated",
        "language": "pt",
        "language_creators": "expert-generated",
        "license": "apache-2.0",
        "multilinguality": "multilingual",
        "size_categories": "10K<n<100K",
        "source_datasets": "original",
        "task_categories": "question-answering",
        "task_ids": "multiple-choice-qa",
        "region": "global"
    },
    "__description__": "Global-MMLU is a multilingual evaluation set spanning 42 languages, combining machine translations for MMLU questions along with professional translations and crowd-sourced post-edits. The dataset includes cultural sensitivity annotations, classifying questions as Culturally Sensitive (CS) or Culturally Agnostic (CA)ï¸. This initiative was led by Cohere For AI in collaboration with external contributors from industry and academia. The test spans subjects in humanities, social sciences, hard sciences, and other areas. See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU"
}
