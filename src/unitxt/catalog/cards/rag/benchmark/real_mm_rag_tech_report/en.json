{
    "__type__": {
        "module": "unitxt.card",
        "name": "TaskCard"
    },
    "loader": {
        "__type__": {
            "module": "unitxt.loaders",
            "name": "LoadHF"
        },
        "path": "ibm-research/REAL-MM-RAG_TechReport",
        "name": "default",
        "split": "test",
        "data_classification_policy": [
            "public"
        ]
    },
    "preprocess_steps": [
        {
            "__type__": {
                "module": "unitxt.operators",
                "name": "FilterByCondition"
            },
            "values": {
                "query": null
            },
            "condition": "ne"
        },
        {
            "__type__": {
                "module": "unitxt.image_operators",
                "name": "HashImage"
            },
            "field": "image",
            "to_field": "reference_context_ids"
        },
        {
            "__type__": {
                "module": "unitxt.operators",
                "name": "Copy"
            },
            "field": "query",
            "to_field": "question"
        },
        {
            "__type__": {
                "module": "unitxt.operators",
                "name": "AddIncrementalId"
            },
            "to_field": "question_id"
        },
        {
            "__type__": {
                "module": "unitxt.operators",
                "name": "Cast"
            },
            "field": "question_id",
            "to": "str"
        },
        {
            "__type__": {
                "module": "unitxt.splitters",
                "name": "SplitRandomMix"
            },
            "mix": {
                "test": "test[30%]",
                "train": "test[70%]"
            }
        },
        {
            "__type__": {
                "module": "unitxt.collections_operators",
                "name": "Wrap"
            },
            "field": "answer",
            "inside": "list",
            "to_field": "reference_answers"
        },
        {
            "__type__": {
                "module": "unitxt.collections_operators",
                "name": "Wrap"
            },
            "field": "reference_context_ids",
            "inside": "list",
            "to_field": "reference_context_ids"
        }
    ],
    "task": "tasks.rag.end_to_end",
    "templates": {
        "default": "templates.rag.end_to_end.json_predictions"
    },
    "__tags__": {
        "license": "cdla-permissive-2.0",
        "url": "https://huggingface.co/datasets//ibm-research/REAL-MM-RAG_TechReport"
    },
    "__title__": "REALMMRAG: TechReport",
    "__description__": "We introduced REAL-MM-RAG-Bench, a real-world multi-modal retrieval benchmark designed to evaluate retrieval models in reliable, challenging, and realistic settings. The benchmark was constructed using an automated pipeline, where queries were generated by a vision-language model (VLM), filtered by a large language model (LLM), and rephrased by an LLM to ensure high-quality retrieval evaluation. To simulate real-world retrieval challenges, we introduce multi-level query rephrasing, modifying queries at three distinct levels—from minor wording adjustments to significant structural changes—ensuring models are tested on their true semantic understanding rather than simple keyword matching."
}
