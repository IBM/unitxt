{
    "__type__": {
        "module": "unitxt.card",
        "name": "TaskCard"
    },
    "loader": {
        "__type__": {
            "module": "unitxt.loaders",
            "name": "LoadHF"
        },
        "path": "baharef/ToT",
        "name": "tot_arithmetic"
    },
    "preprocess_steps": [
        {
            "__type__": {
                "module": "unitxt.string_operators",
                "name": "Replace"
            },
            "field": "label",
            "old": "'",
            "new": "\""
        },
        {
            "__type__": {
                "module": "unitxt.struct_data_operators",
                "name": "LoadJson"
            },
            "field": "label"
        },
        {
            "__type__": {
                "module": "unitxt.operators",
                "name": "Copy"
            },
            "field": "label/answer",
            "to_field": "label"
        }
    ],
    "task": {
        "__type__": {
            "module": "unitxt.task",
            "name": "Task"
        },
        "input_fields": {
            "question": "str"
        },
        "reference_fields": {
            "label": "str"
        },
        "prediction_type": "str",
        "metrics": [
            "metrics.accuracy"
        ]
    },
    "templates": [
        {
            "__type__": {
                "module": "unitxt.templates",
                "name": "InputOutputTemplate"
            },
            "input_format": "{question}",
            "output_format": "{{\"answer\": \"{label}\"}}",
            "postprocessors": [
                {
                    "__type__": {
                        "module": "unitxt.processors",
                        "name": "PostProcess"
                    },
                    "operator": {
                        "__type__": {
                            "module": "unitxt.processors",
                            "name": "ExtractWithRegex"
                        },
                        "regex": "\"answer\"\\s*:\\s*\"((?:[^\"\\\\]|\\\\.)*)\""
                    }
                }
            ]
        }
    ],
    "__tags__": {
        "license": "cc-by-4.0",
        "language": [
            "en"
        ],
        "task_categories": [
            "question-answering"
        ]
    },
    "__description__": "Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning\nToT is a dataset designed to assess the temporal reasoning capabilities of AI models. It comprises two key sections:\nToT-semantic: Measuring the semantics and logic of time understanding.\nToT-arithmetic: Measuring the ability to carry out time arithmetic operations.\n"
}
