{
    "__type__": "task_card",
    "loader": {
        "__type__": "load_csv",
        "files": {
            "questions": "https://raw.githubusercontent.com/ShishirPatil/gorilla/70b6a4a2144597b1f99d1f4d3185d35d7ee532a4/berkeley-function-call-leaderboard/data/BFCL_v3_simple.json",
            "answers": "https://raw.githubusercontent.com/ShishirPatil/gorilla/70b6a4a2144597b1f99d1f4d3185d35d7ee532a4/berkeley-function-call-leaderboard/data/possible_answer/BFCL_v3_simple.json"
        },
        "file_type": "json",
        "lines": true,
        "data_classification_policy": [
            "public"
        ]
    },
    "preprocess_steps": [
        {
            "__type__": "join_streams",
            "left_stream": "questions",
            "right_stream": "answers",
            "how": "inner",
            "on": "id",
            "new_stream_name": "test"
        },
        {
            "__type__": "copy",
            "field": "question/0/0/content",
            "to_field": "query"
        },
        {
            "__type__": "copy",
            "field": "function",
            "to_field": "tools"
        },
        {
            "__type__": "recursive_replace",
            "key": "type",
            "map_values": {
                "dict": "object",
                "float": "number",
                "tuple": "array"
            },
            "remove_values": [
                "any"
            ]
        },
        {
            "__type__": "execute_expression",
            "expression": "[{\"name\": k, \"arguments\": dict(zip(v.keys(), vals))} for d in ground_truth for k, v in d.items() for vals in itertools.product(*v.values())]",
            "to_field": "reference_calls",
            "imports_list": [
                "itertools"
            ]
        }
    ],
    "task": "tasks.tool_calling.supervised",
    "templates": [
        "templates.tool_calling.base"
    ],
    "__description__": "The Berkeley function calling leaderboard is a live leaderboard to evaluate the ability of different LLMs to call functions (also referred to as tools). We built this dataset from our learnings to be representative of most users' function calling use-cases, for example, in agents, as a part of enterprise workflows, etc. To this end, our evaluation dataset spans diverse categories, and across multiple languages.",
    "__title__": "Berkeley Function Calling Leaderboard - Simple V3",
    "__tags__": {
        "annotations_creators": "expert-generated",
        "language": [
            "en"
        ],
        "license": "apache-2.0",
        "size_categories": [
            "10K<n<100K"
        ],
        "task_categories": [
            "question-answering",
            "reading-comprehension",
            "tool-calling"
        ],
        "task_ids": [
            "tool-calling",
            "reading-comprehension"
        ]
    }
}
