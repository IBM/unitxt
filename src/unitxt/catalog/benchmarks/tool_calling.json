{
    "__type__": {
        "module": "unitxt.benchmark",
        "name": "Benchmark"
    },
    "subsets": {
        "bfcl.simple": {
            "__type__": {
                "module": "unitxt.standard",
                "name": "DatasetRecipe"
            },
            "card": "cards.bfcl.multi_turn.simple_v3",
            "format": "formats.chat_api",
            "metrics": [
                "metrics.tool_calling.multi_turn.validity",
                "metrics.tool_calling.multi_turn.correctness.llama_3_3_70b_instruct_judge"
            ]
        },
        "bfcl.multiple": {
            "__type__": {
                "module": "unitxt.standard",
                "name": "DatasetRecipe"
            },
            "card": "cards.bfcl.multi_turn.multiple_v3",
            "format": "formats.chat_api",
            "metrics": [
                "metrics.tool_calling.multi_turn.validity",
                "metrics.tool_calling.multi_turn.correctness.llama_3_3_70b_instruct_judge"
            ]
        },
        "bfcl.live_multiple": {
            "__type__": {
                "module": "unitxt.standard",
                "name": "DatasetRecipe"
            },
            "card": "cards.bfcl.multi_turn.live_multiple_v3",
            "format": "formats.chat_api",
            "metrics": [
                "metrics.tool_calling.multi_turn.validity",
                "metrics.tool_calling.multi_turn.correctness.llama_3_3_70b_instruct_judge"
            ]
        },
        "bfcl.live_simple": {
            "__type__": {
                "module": "unitxt.standard",
                "name": "DatasetRecipe"
            },
            "card": "cards.bfcl.multi_turn.live_simple_v3",
            "format": "formats.chat_api",
            "metrics": [
                "metrics.tool_calling.multi_turn.validity",
                "metrics.tool_calling.multi_turn.correctness.llama_3_3_70b_instruct_judge"
            ]
        },
        "bfcl.java": {
            "__type__": {
                "module": "unitxt.standard",
                "name": "DatasetRecipe"
            },
            "card": "cards.bfcl.multi_turn.java_v3",
            "format": "formats.chat_api",
            "metrics": [
                "metrics.tool_calling.multi_turn.validity",
                "metrics.tool_calling.multi_turn.correctness.llama_3_3_70b_instruct_judge"
            ]
        },
        "bfcl.javascript": {
            "__type__": {
                "module": "unitxt.standard",
                "name": "DatasetRecipe"
            },
            "card": "cards.bfcl.multi_turn.javascript_v3",
            "format": "formats.chat_api",
            "metrics": [
                "metrics.tool_calling.multi_turn.validity",
                "metrics.tool_calling.multi_turn.correctness.llama_3_3_70b_instruct_judge"
            ]
        },
        "bfcl.parallel": {
            "__type__": {
                "module": "unitxt.standard",
                "name": "DatasetRecipe"
            },
            "card": "cards.bfcl.multi_turn.parallel_v3",
            "format": "formats.chat_api",
            "metrics": [
                "metrics.tool_calling.multi_turn.validity",
                "metrics.tool_calling.multi_turn.correctness.llama_3_3_70b_instruct_judge"
            ]
        },
        "bfcl.parallel_multiple": {
            "__type__": {
                "module": "unitxt.standard",
                "name": "DatasetRecipe"
            },
            "card": "cards.bfcl.multi_turn.parallel_multiple_v3",
            "format": "formats.chat_api",
            "metrics": [
                "metrics.tool_calling.multi_turn.validity",
                "metrics.tool_calling.multi_turn.correctness.llama_3_3_70b_instruct_judge"
            ]
        },
        "bfcl.live_parallel": {
            "__type__": {
                "module": "unitxt.standard",
                "name": "DatasetRecipe"
            },
            "card": "cards.bfcl.multi_turn.live_parallel_v3",
            "format": "formats.chat_api",
            "metrics": [
                "metrics.tool_calling.multi_turn.validity",
                "metrics.tool_calling.multi_turn.correctness.llama_3_3_70b_instruct_judge"
            ]
        },
        "bfcl.live_parallel_multiple": {
            "__type__": {
                "module": "unitxt.standard",
                "name": "DatasetRecipe"
            },
            "card": "cards.bfcl.multi_turn.live_parallel_multiple_v3",
            "format": "formats.chat_api",
            "metrics": [
                "metrics.tool_calling.multi_turn.validity",
                "metrics.tool_calling.multi_turn.correctness.llama_3_3_70b_instruct_judge"
            ]
        },
        "xlam": {
            "__type__": {
                "module": "unitxt.standard",
                "name": "DatasetRecipe"
            },
            "card": "cards.xlam_function_calling_60k",
            "format": "formats.chat_api",
            "metrics": [
                "metrics.tool_calling.multi_turn.validity",
                "metrics.tool_calling.multi_turn.correctness.llama_3_3_70b_instruct_judge"
            ]
        }
    }
}
