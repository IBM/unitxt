{
    "type": "llm_as_judge",
    "inference_model": {
        "type": "hf_pipeline_based_inference_engine",
        "model_name": "google/flan-t5-large",
        "max_new_tokens": 32
    },
    "recipe": "card=cards.llm_as_judge.model_response_assessment.mt_bench,template=templates.llm_as_judge.model_response_assessment.mt_bench,demos_pool_size=0,num_demos=0"
}
