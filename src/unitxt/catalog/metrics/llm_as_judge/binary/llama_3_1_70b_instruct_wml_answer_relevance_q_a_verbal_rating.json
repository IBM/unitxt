{
    "__type__": "task_based_ll_mas_judge",
    "inference_model": "engines.classification.llama_3_1_70b_instruct_wml",
    "template": "templates.rag_eval.answer_relevance.judge_answer_relevance_verbal_rating",
    "task": "tasks.rag_eval.answer_relevance.binary",
    "format": null,
    "main_score": "answer_relevance_q_a_verbal_rating",
    "prediction_field": "answer",
    "infer_log_probs": false
}
