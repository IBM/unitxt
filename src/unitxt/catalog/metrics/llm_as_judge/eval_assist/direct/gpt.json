{
    "__type__": "eval_assist_llm_as_judge",
    "inference_model": {
        "__type__": "open_ai_inference_engine",
        "model_name": "gpt-4o-2024-05-13",
        "parameters": {
            "__type__": "open_ai_inference_engine_params_mixin",
            "max_tokens": 1024,
            "seed": 42
        }
    },
    "assessment_template": {
        "__type__": "input_output_template",
        "input_format": "You are presented with a response generated to satisfy an instruction. \nYou will assess the quality of the response subject to an evaluation criteria.\n###Context:\n{context_variables}\n###Response:\n{response}\n###Evaluation criteria:\n{criteria}\n{options}\nBriefly assess the quality of the response subject to the evaluation criteria.\nFocus on the evaluation criteria during assessment, do not provide a general assessment.\nAssessment: \n"
    },
    "summ_template": {
        "__type__": "input_output_template",
        "input_format": "Summarize the following assessment into an single easy to understand statement.\nAssessment: {assessment}\nAssessment Summary:\n"
    },
    "answer_template": {
        "__type__": "input_output_template",
        "input_format": "Now consider the evaluation criteria and choose a final answer. \nValidate the answer against the assessment.\n###Evaluation criteria:\n{criteria}\n{options}\nAnswer: "
    }
}
