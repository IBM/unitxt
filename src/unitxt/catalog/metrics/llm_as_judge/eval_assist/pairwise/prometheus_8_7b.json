{
    "__type__": "eval_assist_llm_as_judge_pairwise",
    "inference_model": {
        "__type__": "ibm_gen_ai_inference_engine",
        "model_name": "kaist-ai/prometheus-8x7b-v2",
        "data_classification_policy": [
            "public"
        ],
        "max_new_tokens": 1024,
        "random_seed": 42
    },
    "assessment_template": {
        "__type__": "input_output_template",
        "input_format": "###Task Description:\nA context that includes information relevant to the nature or generation of the response, a response to evaluate, and a score rubric representing a evaluation criteria are given.\n1. Write a detailed feedback that assess the quality of two responses strictly based on the given score rubric, not evaluating in general.\n2. After writing a feedback, choose a better response between Response {option_a} and Response {option_b}. You should refer to the score rubric.\n3. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] ({option_a} or {option_b})\"\n4. Please do not generate any other opening, closing, and explanations.\n###Context:\n{context_variables}\n###Response {option_a}:\n{response_a}\n###Response {option_b}:\n{response_b}\n###Score Rubric:\n{rubric}\n###Feedback: \n"
    },
    "summ_template": null,
    "answer_template": null
}
