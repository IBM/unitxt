# replaces the __description__ contents of card generators, if exists, by content coming from Michal Jacovi,
# in the following format:
# Descriptions of HF datasets, extracted through ds_info.description
# (https://huggingface.co/docs/huggingface_hub/v0.23.2/package_reference/hf_api)

# =============================================================
# Card name: 20_newsgroups   Full file path: /home/dafna/workspaces/unitxt/prepare/cards/20_newsgroups.py
# Url at HF: https://huggingface.co/datasets/SetFit/20_newsgroups

# -------------------------------------------------------
# This is a version of the 20 newsgroups dataset that is provided in Scikit-learn. From the Scikit-learn docs:
# "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date."
# See the full description on the dataset page: https://huggingface.co/datasets/SetFit/20_newsgroups.
# -----------------------------------------------------
# =============================================================
# Card name: 20newsgroups_sklearn   Full file path: /home/dafna/workspaces/unitxt/prepare/cards/20newsgroups_sklearn.py
# =============================================================
# Card name: CFPB_product   Full file path: /home/dafna/workspaces/unitxt/prepare/cards/CFPB_product.py
# =============================================================
# Card name: ag_news   Full file path: /home/dafna/workspaces/unitxt/prepare/cards/ag_news.py
# Url at HF: https://huggingface.co/datasets/ag_news

# -------------------------------------------------------
# AG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of activity. ComeToMyHead is an academic news search engine which has been running since July, 2004. The dataset is provided by the academic community for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fancyzhx/ag_news.
# -----------------------------------------------------
# =============================================================
# ...
# that is: a line of ========= separates between the card generating files,
# followed by two lines of details about that file
# and then, if description exists and sent for update, or a new description is generated by Michal, it shows between two
# -------  lines, and only there.
# line breaks that Michal decides upon are maintained all the way to the website.
#
import logging
import os
import re

from ..logging_utils import get_logger
from ..text_utils import lines_defining_obj_in_card

logger = get_logger()
logger.setLevel(logging.INFO)
# so, with settings.default_verbosity = "critical", only this module catches stdout and stderr
project_dir = os.path.dirname(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
)
logger.info("project_dir: ", project_dir)
with open("all_descs.mj.txt") as mj_file:
    all_mj_lines = mj_file.readlines()

mj_current_line_no = 0
while mj_current_line_no < len(all_mj_lines):
    while not all_mj_lines[mj_current_line_no].startswith("===============") and (
        mj_current_line_no < len(all_mj_lines)
    ):
        mj_current_line_no += 1
    if not all_mj_lines[mj_current_line_no].startswith("==============="):
        break
    # move on to the first line with card details
    mj_current_line_no += 1
    card_full_file_path = re.search(
        r" Full file path: (.*)\n", all_mj_lines[mj_current_line_no]
    )
    if card_full_file_path is None:
        raise ValueError(
            f"Could not find file full path in line no {mj_current_line_no}"
        )
    card_full_file_path = card_full_file_path.group(1)
    logger.info(f"updating description for file {card_full_file_path}")
    mj_current_line_no += 1
    while (
        not all_mj_lines[mj_current_line_no].startswith("===============")
        and (mj_current_line_no < len(all_mj_lines))
        and not all_mj_lines[mj_current_line_no].startswith("----------------")
    ):
        mj_current_line_no += 1
    if mj_current_line_no >= len(all_mj_lines):
        break
    if all_mj_lines[mj_current_line_no].startswith("==============="):
        mj_current_line_no += 1
        continue
    new_desc_lines = []
    mj_current_line_no += 1
    while (
        not all_mj_lines[mj_current_line_no].startswith("===============")
        and (mj_current_line_no < len(all_mj_lines))
        and not all_mj_lines[mj_current_line_no].startswith("----------------")
    ):
        new_desc_lines.append(all_mj_lines[mj_current_line_no])
        mj_current_line_no += 1

    # if no new desc for this card_file -- do not touch it, and continue to next card file in all_descs input file
    if len(new_desc_lines) == 0:
        mj_current_line_no += 1
        continue

    # prepare the new desc_lines to print
    for i in range(len(new_desc_lines)):
        new_desc_lines[i] = new_desc_lines[i][:-1]  # remove the ending \n
    for i in range(len(new_desc_lines)):
        new_desc_lines[i] = new_desc_lines[i].replace('"', '\\"') + "\\n"
    new_desc_lines[-1] = new_desc_lines[-1][
        :-2
    ]  # remove the \n at the end of the last line
    for i in range(len(new_desc_lines)):
        new_desc_lines[i] = '"' + new_desc_lines[i] + '"\n'
    # an updated desc exists for card_file, retrieve retrieve the card file to be updated,
    # and proceed down to currently existing __description__ tag (if any), while
    # preparing the updated lines to be written to that file:
    to_lines = []
    with open(card_full_file_path) as fp:
        all_lines = fp.readlines()
    current_line = 0
    while True:
        # locate next definition of TaskCard in the input file
        starting_card, ending_card = lines_defining_obj_in_card(
            all_lines=all_lines, obj_name="TaskCard(", start_search_at_line=current_line
        )
        if starting_card == -1:
            # no more task_cards in file
            to_lines.extend(all_lines[current_line:])
            with open(card_full_file_path, "w") as fp2:
                fp2.writelines(to_lines)
            break

        # the indent of the _description__ tag exceeds by 4 the indent of the closing ) of the taskCard:
        tags_indent = " " * (4 + all_lines[ending_card].index(")"))
        # we have a taskcard to update
        # copy all lines down to start of this taskcard on to the annotated file

        to_lines.extend(all_lines[current_line:starting_card])
        current_line = starting_card

        starting_tags_in_card, ending_tags_in_card = lines_defining_obj_in_card(
            all_lines=all_lines[starting_card:ending_card],
            obj_name="__description__",
            # all_lines=all_lines[starting_card:ending_card], obj_name="__tags__"
        )
        if starting_tags_in_card == -1:
            # no __description__ in card, insert the new desc at the end of the TaskCard:
            to_lines.extend(all_lines[current_line:ending_card])
            current_line = ending_card
            to_lines.append(tags_indent + "__description__=(\n")
            for desc_line in new_desc_lines:
                to_lines.append(tags_indent + "    " + desc_line)
            to_lines.append(tags_indent + "),\n")
            continue  # to next occurrence of TaskCard( in file

        # there was __description__ in this card, replace its content:
        to_lines.extend(all_lines[current_line : starting_card + starting_tags_in_card])
        to_lines.append(tags_indent + "__description__=(\n")
        for desc_line in new_desc_lines:
            to_lines.append(tags_indent + "    " + desc_line)
        to_lines.append(tags_indent + "),\n")

        # skip the input lines that belonged to the existing __tags__
        current_line = starting_card + ending_tags_in_card + 1
        # and copy over all lines down to the end of the card
        to_lines.extend(all_lines[current_line:ending_card])
        current_line = ending_card

    mj_current_line_no += 1
    continue
